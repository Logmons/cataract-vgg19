import os  # Module pour interagir avec le syst√®me d'exploitation (gestion des fichiers, dossiers, etc.)
import numpy as np  # Biblioth√®que pour l'alg√®bre lin√©aire et les calculs num√©riques
import pandas as pd  # Biblioth√®que pour la manipulation et l'analyse des donn√©es
import cv2  # OpenCV pour le traitement des images
import random  # Module pour g√©n√©rer des nombres al√©atoires
from tqdm import tqdm  # Permet d'afficher une barre de progression lors des boucles
import matplotlib.pyplot as plt  # Biblioth√®que pour la visualisation des donn√©es
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # G√©n√©rateur d'images pour l'augmentation des donn√©es

# Chargement du fichier CSV contenant les donn√©es
df = pd.read_csv("./input/full_df.csv")

# Affichage des 3 premi√®res lignes du DataFrame pour v√©rifier le contenu
print (df.head(3))
# Fonction pour v√©rifier si un texte contient le mot "jhcataract"
def has_cataract(text):
    if "cataract" in text:
        return 1
    else:
        return 0
    # Cr√©ation d'une nouvelle colonne "left_cataract" indiquant la pr√©sence de cataracte √† gauche
df["left_cataract"] = df["Left-Diagnostic Keywords"].apply(lambda x: has_cataract(x))
# Cr√©ation d'une nouvelle colonne "right_cataract" indiquant la pr√©sence de cataracte √† droite
df["right_cataract"] = df["Right-Diagnostic Keywords"].apply(lambda x: has_cataract(x))

left_cataract = df.loc[(df.C ==1) & (df.left_cataract == 1)]["Left-Fundus"].values
print (left_cataract[:15])

right_cataract = df.loc[(df.C ==1) & (df.right_cataract == 1)]["Right-Fundus"].values
print (right_cataract[:15])

print("Number of images in left cataract: {}".format(len(left_cataract)))
print("Number of images in right cataract: {}".format(len(right_cataract)))

left_normal = df.loc[(df.C ==0) & (df["Left-Diagnostic Keywords"] == "normal fundus")]["Left-Fundus"].sample(250,random_state=42).values
right_normal = df.loc[(df.C ==0) & (df["Right-Diagnostic Keywords"] == "normal fundus")]["Right-Fundus"].sample(250,random_state=42).values
right_normal[:15]

cataract = np.concatenate((left_cataract,right_cataract),axis=0)
normal = np.concatenate((left_normal,right_normal),axis=0)
# Affichage du nombre total d'images atteintes de cataracte et du nombre total d'images normales
print(len(cataract),len(normal))

from tensorflow.keras.preprocessing.image import load_img,img_to_array
dataset_dir = "./input/prep"
image_size=224
labels = []
dataset = []
# Fonction pour cr√©er un dataset d'images avec leurs labels
def create_dataset(image_category,label):
    for img in tqdm(image_category):
        image_path = os.path.join(dataset_dir,img)
        try:
            # Chargement de l'image en couleur avec OpenCV
            image = cv2.imread(image_path,cv2.IMREAD_COLOR)
            image = cv2.resize(image,(image_size,image_size))
        except:
            continue # Si une erreur se produit (fichier non trouv√©, format incorrect), on passe √† l'image suivante
        
        # Ajout de l'image et du label sous forme de tableau NumPy dans la liste dataset
        dataset.append([np.array(image),np.array(label)])
    random.shuffle(dataset)
    return dataset
        
dataset = create_dataset(cataract,1)
print("Nombre d'images atteintes de cataracte :", len(dataset))
dataset = create_dataset(normal,0)
print("Nombre d'images normales :", len(dataset))
# Affichage de 10 images al√©atoires du dataset
plt.figure(figsize=(12,7))
for i in range(10):
    sample = random.choice(range(len(dataset)))
    image = dataset[sample][0]
    category = dataset[sample][1]
    if category== 0:
        label = "Normal"
    else:
        label = "Cataract"
    plt.subplot(2,5,i+1)
    plt.imshow(image)
    plt.xlabel(label)
    plt.tight_layout()    
# Cr√©ation d'un tableau NumPy contenant toutes les images et les labels
x = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3)
y = np.array([i[1] for i in dataset])
from sklearn.model_selection import train_test_split
# S√©paration des donn√©es en ensembles d'entra√Ænement et de test
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Cr√©ation du g√©n√©rateur d'entra√Ænement avec augmentation des donn√©es
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)

# G√©n√©rateur pour les donn√©es de validation (sans augmentation, juste normalisation)
val_datagen = ImageDataGenerator(rescale=1./255)

# Application du g√©n√©rateur sur les donn√©es numpy
train_generator = train_datagen.flow(x_train, y_train, batch_size=32)
val_generator = val_datagen.flow(x_test, y_test, batch_size=32)

from tensorflow.keras.applications.vgg19 import VGG19
# Chargement du mod√®le VGG19 pr√©-entra√Æn√© sans la couche de classification finale (include_top=False)
vgg = VGG19(weights="imagenet",include_top = False,input_shape=(image_size,image_size,3))
# D√©sactivation de l'entra√Ænement de toutes les couches du mod√®le VGG19
for layer in vgg.layers:
    layer.trainable = False
from tensorflow.keras import Sequential  # Importation du mod√®le s√©quentiel de Keras
from tensorflow.keras.layers import Flatten, Dense  # Importation des couches n√©cessaires

from tensorflow.keras.layers import Dropout  # üëâ Mets √ßa en haut avant le mod√®le

# Cr√©ation d'un mod√®le s√©quentiel
model = Sequential()
model.add(vgg)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation="sigmoid"))



# Affichage du r√©sum√© du mod√®le pour inspecter la structure
model.summary()

# Cr√©ation d'un mod√®le nomm√© "Cataract_Model"
Model = Sequential(name="Cataract_Model")

# Compilation du mod√®le avec l'optimiseur "adam", la fonction de perte "binary_crossentropy" 
# pour une classification binaire, et la m√©trique "accuracy" pour √©valuer les performances
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

from tensorflow.keras.callbacks import ModelCheckpoint  # Importation de la fonction de rappel pour enregistrer le mod√®le pendant l'entra√Ænement

# D√©finition d'un callback pour enregistrer le mod√®le avec la meilleure validation
checkpoint = ModelCheckpoint("vgg19.keras", 
                             monitor="val_accuracy",  # Surveille la pr√©cision de validation
                             verbose=1,  # Affiche des informations pendant l'entra√Ænement
                             save_best_only=True,  # Enregistre uniquement si la pr√©cision de validation est am√©lior√©e
                             save_weights_only=False,  # Enregistre le mod√®le complet, pas seulement les poids
                             save_freq='epoch')  # Sauvegarde √† chaque √©poque


from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)

# Entra√Ænement du mod√®le avec les donn√©es d'entra√Ænement, de validation et les callbacks
history = model.fit(
    train_generator,
    epochs=15,
    validation_data=val_generator,
    verbose=1,
    callbacks=[checkpoint, reduce_lr]
)

# √âvaluation du mod√®le sur les donn√©es de test
loss, accuracy = model.evaluate(x_test, y_test)  # Calcule la perte et la pr√©cision sur l'ensemble de test
print("loss:", loss)  # Affiche la perte (loss)
print("Accuracy:", accuracy)  # Affiche la pr√©cision (accuracy)

# Importation des outils pour g√©n√©rer des m√©triques de classification
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Pr√©diction des labels sur les donn√©es de test et conversion des probabilit√©s en classes (0 ou 1)
y_pred = (model.predict(x_test) > 0.5).astype("int32")  # ‚úÖ Si la probabilit√© est sup√©rieure √† 0.5, classe 1 (cataracte), sinon 0 (normal)

# Calcul de la pr√©cision en comparant les valeurs pr√©dites avec les valeurs r√©elles
accuracy_score(y_test, y_pred)  # Calcul de la pr√©cision globale

# Importation de la fonction pour afficher la matrice de confusion
from mlxtend.plotting import plot_confusion_matrix

# Calcul de la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Affichage de la matrice de confusion
plot_confusion_matrix(conf_mat=cm, figsize=(8,7), class_names=["Normal", "Cataract"], show_normed=True);

# Importation de la biblioth√®que matplotlib pour personnaliser l'affichage
import matplotlib.pyplot as plt

# D√©finition du style pour les graphiques
plt.style.use("ggplot")

# Cr√©ation d'une figure pour visualiser les r√©sultats (bien que la visualisation semble incompl√®te ici)
fig = plt.figure(figsize=(12,6))

# Ajuster la longueur des √©poques selon l'historique
epochs = range(1, len(history.history["accuracy"]) + 1)

# Tracer la courbe d'accuracy
plt.subplot(1,2,1)
plt.plot(epochs, history.history["accuracy"], "go-")
plt.plot(epochs, history.history["val_accuracy"], "ro-")
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(["Train", "Validation"], loc="upper left")

# Tracer la courbe de loss
plt.subplot(1,2,2)
plt.plot(epochs, history.history["loss"], "go-")
plt.plot(epochs, history.history["val_loss"], "ro-")
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend(["Train", "Validation"], loc="upper left")

# Affichage du graphique
plt.tight_layout()  # Assure que les sous-graphes ne se chevauchent pas
plt.show()
plt.figure(figsize=(12,7))
for i in range(15):
    sample = random.choice(range(len(x_test)))
    image = x_test[sample]
    category = y_test[sample]
    pred_category = y_pred[sample]
    
    if category== 0:
        label = "Normal"
    else:
        label = "Cataract"
        
    if pred_category== 0:
        pred_label = "Normal"
    else:
        pred_label = "Cataract"
        
    plt.subplot(2,5,i+1)
    plt.imshow(image)
    plt.xlabel("Actual:{}\nPrediction:{}".format(label,pred_label))
plt.tight_layout() 


